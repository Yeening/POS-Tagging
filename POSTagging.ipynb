{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "K = 2\n",
    "alpha = 1\n",
    "beta = 1\n",
    "\n",
    "def load_data_set(filename):\n",
    "    # your code\n",
    "    tokens = []\n",
    "    tags = []\n",
    "    f = open(filename, 'r')\n",
    "    for line in f:\n",
    "        pairs = line.split()\n",
    "        current_tokens = []\n",
    "        current_tags = []\n",
    "        for pair in pairs:\n",
    "            data = pair.split('/')\n",
    "            current_tokens.append(data[0])\n",
    "            current_tags.append(data[1])\n",
    "        tokens.append(current_tokens)\n",
    "        tags.append(current_tags)\n",
    "    return tokens, tags\n",
    "\n",
    "def preprocessing(tokens,tags):\n",
    "    k = K\n",
    "    dic = {}\n",
    "    prepocessed_tags = deepcopy(tags)\n",
    "    for sentence in tokens:\n",
    "        for token in sentence:\n",
    "            if token in dic:\n",
    "                dic[token] += 1\n",
    "            else:\n",
    "                dic[token] = 1\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(len(tokens[i])):\n",
    "            if dic[tokens[i][j]] < k:\n",
    "                prepocessed_tags[i][j] = \"UNK\"\n",
    "    return prepocessed_tags,dic\n",
    "\n",
    "def get_probilities(tokens,tags,x_dic):\n",
    "    y_dic = {}\n",
    "    y_y_dic = {}\n",
    "    for tag_set in tags:\n",
    "        new_tag_set = list(tag_set)\n",
    "        new_tag_set.insert(0, 'start')\n",
    "        new_tag_set.append('end')\n",
    "        \n",
    "        for i in range(len(new_tag_set)):\n",
    "            if new_tag_set[i] in y_dic:\n",
    "                y_dic[new_tag_set[i]] += 1\n",
    "            else:\n",
    "                y_dic[new_tag_set[i]] = 1\n",
    "            \n",
    "            if i == len(new_tag_set) - 1:\n",
    "                break\n",
    "            \n",
    "            if new_tag_set[i]+'|'+new_tag_set[i+1] in y_y_dic:\n",
    "                y_y_dic[new_tag_set[i]+'|'+new_tag_set[i+1]] += 1\n",
    "            else:\n",
    "                y_y_dic[new_tag_set[i]+'|'+new_tag_set[i+1]] = 1\n",
    "#     print(y_dic,y_y_dic)\n",
    "    p_y_y = y_y_dic.copy()\n",
    "    for y_y in y_y_dic.keys():\n",
    "        p_y_y[y_y] = 0.0\n",
    "        p_y_y[y_y] = (y_y_dic[y_y]+alpha)/(y_dic[y_y.split('|')[0]]+alpha*(len(y_dic)+1))\n",
    "    \n",
    "    x_y_dic = {}\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(len(tokens[i])):\n",
    "            if tokens[i][j]+'|'+tags[i][j] in x_y_dic:\n",
    "                x_y_dic[tokens[i][j]+'|'+tags[i][j]] += 1\n",
    "            else:\n",
    "                x_y_dic[tokens[i][j]+'|'+tags[i][j]] = 1\n",
    "    \n",
    "    p_x_y = {}\n",
    "    for x_y in x_y_dic.keys():\n",
    "        p_x_y[x_y] = 0.0\n",
    "        p_x_y[x_y] = (x_y_dic[x_y]+beta)/(y_dic[x_y.split('|')[1]]+beta*len(x_dic))    \n",
    "    \n",
    "#     count = 0.0\n",
    "#     for x_y in p_x_y.keys():\n",
    "#         if x_y.split('|')[1] == 'C':\n",
    "#             count += p_x_y[x_y]\n",
    "#     print(count)\n",
    "    \n",
    "#     count = 0.0\n",
    "#     for y_y in p_y_y.keys():\n",
    "#         if y_y[0] == 'P':\n",
    "#             count += p_y_y[y_y]\n",
    "#     print(count)\n",
    "    return p_y_y,p_x_y\n",
    "\n",
    "def to_logistic(p_y_y,p_x_y):\n",
    "    log_p_y_y = p_y_y.copy()\n",
    "    log_p_x_y = p_x_y.copy()\n",
    "    for key in log_p_y_y:\n",
    "        log_p_y_y[key] = math.log2(log_p_y_y[key])\n",
    "    for key in log_p_x_y:\n",
    "        log_p_x_y[key] = math.log2(log_p_x_y[key])\n",
    "    return log_p_y_y,log_p_x_y\n",
    "\n",
    "def Viterbi(log_p_y_y,log_p_x_y):\n",
    "    \n",
    "    \n",
    "\n",
    "trn_tokens, trn_tags = load_data_set(\"./data/trn.pos\")\n",
    "prepocessed_tags,x_dic = preprocessing(trn_tokens,trn_tags)\n",
    "\n",
    "# print(len(trn_texts[0]),len(trn_tags[0]))\n",
    "p_y_y,p_x_y = get_probilities(trn_tokens,prepocessed_tags,x_dic)\n",
    "log_p_y_y,log_p_x_y = to_logistic(p_y_y,p_x_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3.7",
   "language": "python",
   "name": "ml3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
